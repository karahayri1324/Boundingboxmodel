# =============================================================================
# REAP V10 - Environment Configuration
# =============================================================================
# Copy this to .env and modify as needed
# =============================================================================

# HuggingFace Token (optional, for private models)
HF_TOKEN=

# =============================================================================
# Model Paths
# =============================================================================

# Source model path (AWQ quantized)
REAP_MODEL_PATH=/app/data/models/Qwen3-VL-235B-A22B-Thinking-AWQ

# Output path for REAP metadata
REAP_OUTPUT_PATH=/app/output/reap-v10

# Output path for pruned model
REAP_PRUNED_OUTPUT_PATH=/app/output/Qwen3-VL-235B-Pruned

# Calibration data path
REAP_CALIBRATION_PATH=/app/data/calibration/calibration_data.json

# =============================================================================
# REAP Settings
# =============================================================================

# Prune ratio (0.40 = prune 40%, keep 60%)
REAP_PRUNE_RATIO=0.40

# Number of calibration samples
REAP_MAX_SAMPLES=300

# Maximum sequence length
REAP_MAX_SEQ_LEN=2048

# Random seed for reproducibility
REAP_SEED=42

# =============================================================================
# H200 GPU Optimization
# =============================================================================

# Total VRAM in GB (H200 = 140GB)
REAP_VRAM_GB=140.0

# VRAM buffer ratio (0.10 = 10% buffer)
REAP_VRAM_BUFFER=0.10

# Number of layers to process in parallel
REAP_PARALLEL_LAYERS=4

# Batch size for processing
REAP_BATCH_SIZE=4

# CUDA device
REAP_DEVICE=cuda:0

# =============================================================================
# CUDA Settings
# =============================================================================

CUDA_VISIBLE_DEVICES=0
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True,max_split_size_mb:512
