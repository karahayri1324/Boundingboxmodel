# =============================================================================
# REAP V11 - Docker Compose
# =============================================================================

services:
  reap:
    build:
      context: .
      dockerfile: Dockerfile
    image: reap-v11:latest
    container_name: reap-v11
    
    stdin_open: true
    tty: true
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    shm_size: '32gb'
    
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - NVIDIA_VISIBLE_DEVICES=all
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True,max_split_size_mb:512
      - HF_HOME=/app/cache/huggingface
      - HF_TOKEN=${HF_TOKEN:-}
      
      # REAP Config
      - REAP_MODEL_PATH=/app/data/models/Qwen3-VL-235B-A22B-Thinking-AWQ
      - REAP_OUTPUT_PATH=/app/output/reap-v11
      - REAP_CALIBRATION_PATH=/app/data/calibration/calibration_data.json
      - REAP_PRUNED_OUTPUT_PATH=/app/output/Qwen3-VL-Pruned-V11
      - REAP_PRUNE_RATIO=0.40
      - REAP_SCORING_MODE=full
      - REAP_MAX_SAMPLES=300
      - REAP_BATCH_SIZE=1
      - REAP_VRAM_GB=140
    
    volumes:
      - /mnt/vault/boundingboxtest:/app/data:rw
      - ./output:/app/output:rw
      - reap-cache:/app/cache
      - ./reap.py:/app/reap.py:ro
      - ./prune_model.py:/app/prune_model.py:ro
      - ./test_pruned_model.py:/app/test_pruned_model.py:ro
    
    working_dir: /app
    
    ulimits:
      memlock:
        soft: -1
        hard: -1
    
    network_mode: host

volumes:
  reap-cache:
    driver: local
